#!/usr/bin/env python

from __future__ import division,print_function,unicode_literals,absolute_import
from pentago import *
from geode import *
import glob
import sys
import re

# Make sure we know which directory we're in
os.chdir(os.path.dirname(__file__))

class Info(object):
  '''Parse timing information out of a log file'''
  def __init__(self,path):
    assert not os.path.islink(path)
    lines = tuple(line.rstrip() for line in open(path))
    times = {}
    walltime = {}
    compression = {}
    balance = {}
    papi = {}
    def re_find(pattern,lo,hi=len(lines)):
      pat = re.compile(pattern)
      for i in xrange(lo,hi):
        m = pat.match(lines[i])
        if m:
          return i,m
      raise RuntimeError('path %s: pattern not found: %s'%(path,pattern))
    self.ranks = int(re_find(r'^\s+ranks = (\d+)$',0,10)[1].group(1))
    for slice in range(36)+['all']:
      if '/all-1' in path and slice in (16,'all'):
        continue # Skip over crash
      if slice=='all':
        hi,_ = re_find('  memory final: virtual',0)
        lo,_ = re_find('  END slice %d\s+(\d+\.\d+) s$'%min(walltime.keys()),0)
        lo += 1
      else:
        try:
          lo = lines.index('  slice %d'%slice)
        except ValueError:
          continue
        hi,m = re_find('  END slice %d\s+(\d+\.\d+) s$'%slice,lo)
        walltime[slice] = float(m.group(1))
        load = lines.index('    load balance',lo,hi)
        for kind in 'lines','line blocks','line nodes','blocks','block nodes':
          _,m = re_find('^      %s = (\d+) (\d+) \((\d+\.?\d*|inf)\)$'%kind,load,load+7)
          balance[slice,kind] = float(m.group(3))
      timing_lo,_ = re_find('\s+timing ?$',lo,hi)
      speeds,_ = re_find('\s+speeds$',lo,hi)
      try:
        papi_lo,m = re_find('\s+papi\s+((?:PAPI_\w+\s*)+)$',lo,hi)
        self.papi_events = m.group(1).split()
        timing_hi = papi_lo
        papi_hi = speeds
      except RuntimeError:
        papi_lo = None
        timing_hi = speeds
      times[slice,'total'] = float(re.match('\s+total (\d+\.\d+)$',lines[timing_hi-1]).group(1))
      if slice != 'all':
        m = re_find(r'^    compression ratio = (0\.\d+) \+- 0\.\d+$',lo,hi)[1]
        compression[slice] = float(m.group(1))
      for i in xrange(timing_lo+1,timing_hi-2):
        m = re.match(r'^\s+(\w+)\s+(\d+\.\d+) s$',lines[i])
        if not m:
          raise RuntimeError('weird time: %s'%lines[i])
        times[slice,bytes.decode(m.group(1))] = float(m.group(2))
      if papi_lo is not None:
        for i in xrange(papi_lo+1,papi_hi-1):
          m = re.match(r'^\s+(\w+)((?:\s+\d+)+)$',lines[i])
          if not m:
            raise RuntimeError('weird papi: %s'%lines[i])
          papi[slice,bytes.decode(m.group(1))] = map(int,m.group(2).split())
    # Remember
    self.times = times
    self.walltime = walltime
    self.compression = compression
    self.balance = balance
    self.papi = papi

# Parse timing information out of all-1 log
all_info = Info('../data/edison/project/all-1/log')

# Total time from up through slice 19 (bulk of compute without the I/O stages)
most = sum(all_info.walltime[n] for n in xrange(19,36))
most_without_io = sum(all_info.walltime[n]
  -sum(all_info.times[n,'write_'+k] for k in ('sparse','counts'))/all_info.ranks for n in xrange(19,36))
print('\nmost time = %g s (%g hours)'%(most,most/3600))
print('most without I/O = %g s (%g hours)'%(most_without_io,most_without_io/3600))

# Measured I/O bandwidth
def io():
  print('\nMeasured I/O bandwidth:')
  ranks = all_info.ranks
  sizes = {'slice-17.pentago':1475380615039,'slice-18.pentago':1954957518434}
  ns = arange(17,36)[::-1]
  sparse_size = []
  sparse_time = []
  for n in ns:
    for kind in ['sparse']+['sections']*(n<19):
      time = all_info.times[n,'write_'+kind]
      name = ('slice-%d.pentago' if kind=='sections' else 'sparse-%d.npy')%n
      size = sizes[name] if name in sizes else os.stat('../data/edison/project/all/'+name).st_size
      if kind=='sparse':
        sparse_time.append(time)
        sparse_size.append(size)
      print('slice %d write %s bandwidth = %d / (%g s / %d) = %g GB/s'%(
        n,kind,size,time,ranks,size/(time/ranks)/2**30))
  read_nodes,read_time = 192,3383.3559 # From data/edison/project/restart-5/log
  size = sizes['slice-17.pentago']
  read_speed = size/read_time
  print('slice 17 read bandwidth (%d nodes) = %d / %g s = %g GB/s'%(
    read_nodes,size,read_time,read_speed/2**30))
  print('  per node: measured = %g MB/s, theoretical peak = %g MB/s'%(
    read_speed/read_nodes/2**20,168*2**30/5192/2**20))
  if 'plot-io' in sys.argv:
    import pylab
    pylab.plot(sparse_size,asarray(sparse_time)/ranks,'o')
    pylab.ylim(0,38e5/ranks)
    pylab.xlabel('sparse-<n>.npy file size')
    pylab.ylabel('write time (s)')
    pylab.show()
io()

# Maximum memory
def peak():
  peak_memory = 0
  for n in xrange(19,34):
    def f(n):
      return all_info.compression[n]*64*count_boards(n,2048)
    peak_memory = max(peak_memory,f(n)+f(n+1))
  print('\npeak memory = %g TB'%(peak_memory/2**40))
peak()

def uncompressed_io():
  '''Estimate the total time Edison would take to do uncompressed I/O'''
  data = 0
  snappy_data = 0
  for n in xrange(35+1):
    d = 64*count_boards(n,2048)
    data += d
    snappy_data += d*all_info.compression.get(n,all_info.compression[17])
  speed = 168*2**30
  fraction = 2048/5192
  time = (1+4)*data/(fraction*speed)
  snappy_time = (1+4)*snappy_data/(fraction*speed)
  print('\nTotal I/O time estimates:')
  print('I/O / data = 5 (1 write + 4 read)')
  print('total data = %g TB (snappy %g TB, ratio %g)'%(data/2**40,snappy_data/2**40,snappy_data/data))
  print('total I/O = %g TB (snappy %g TB)'%((1+4)*data/2**40,(1+4)*snappy_data/2**40))
  print('Peak I/O bandwidth for all of Edison = %g GB/s'%(speed/2**30))
  print('Peak I/O bandwidth for 2048/5192 of Edison (what I used) = %g GB/s'%(fraction*speed/2**30))
  print('uncompressed I/O time estimate = %g hours (snappy %g hours)'%(time/3600,snappy_time/3600))
uncompressed_io()

def sse():
  print('\nSSE vs. non-SSE speedup:')
  def times(pattern):
    return asarray([Info(p).times['all','compute'] for p in glob.glob(pattern)])
  def speedup(lo,hi):
    print('lo = %g +- %g, ratio %g'%(mean(lo),std(lo,ddof=1),std(lo,ddof=1)/mean(lo)))
    print('hi = %g +- %g, ratio %g'%(mean(hi),std(hi,ddof=1),std(hi,ddof=1)/mean(hi)))
    return min(hi)/min(lo)
  sse   = times('../data/edison/project/small-[14]-sse/log')
  nosse = times('../data/edison/project/small-[23]-nosse/log')
  print('edison = %g'%speedup(sse,nosse))
  sse   = times('../data/cayley/sse/small-sse-?/log')
  nosse = times('../data/cayley/sse/small-nosse-?/log')
  print('cayley = %g'%speedup(sse,nosse))
sse()

def idle():
  for with_io in 1,0:
    print('\nIdle vs. total time (%s I/O):'%('with' if with_io else 'without'))
    idle = 0
    total = 0
    for n in xrange(17,35+1):
      i = all_info.times[n,'cpu_idle']
      t = sum(all_info.times.get((n,k),0) for k in '''cpu_idle compress snappy unsnappy compute filter copy
                                                      schedule accumulate allocate_line wakeup compacting'''.split())
      if not with_io:
        w = sum(all_info.times.get((n,'write_'+k),0) for k in 'counts sections sparse'.split())
        i -= 5*w
        t -= 5*w
      print('n %2d : %g / %g = %g'%(n,i,t,i/t))
      idle += i
      total += t
    print('>=17 : %g / %g = %g'%(idle,total,idle/total))
idle()

def snappy():
  snappy = 0
  compute = 0
  for n in xrange(19,35+1):
    snappy += all_info.times[n,'snappy']+all_info.times.get((n,'unsnappy'),0)
    compute += all_info.times[n,'compute']
  total = snappy+compute
  print('\nsnappy fraction = %g / %g = %g'%(snappy,total,snappy/total))
snappy()

def profile():
  import pylab
  names = [('idle due to write','write_sections write_counts write_sparse','y'),
           ('idle','cpu_idle master_idle','r'),
           ('lzma compress','compress','m'),
           ('snappy compress','snappy','b'),
           ('snappy uncompress','unsnappy','c'),
           ('compute','compute','g'),
           ('other','filter copy schedule mpi partition accumulate allocate_line wakeup compacting','k'),
           ('ignore','mpi request_send response_send response_recv wait output_send output_recv total decompress','')]
  for n,kind in all_info.times.keys():
    for _,kinds,_ in names:
      if kind in kinds:
        break
    else:
      raise RuntimeError("missing kind '%s', n %s"%(kind,n))
  ns = asarray(range(17,36)[::-1])
  def time(kinds):
    return asarray([sum(all_info.times.get((n,kind),0) for kind in kinds.split()) for n in ns])
  write = time('write_sections write_counts write_sparse')
  plots = []
  labels = []
  def run(plot,scale=1):
    total = zeros(len(ns))
    for label,kinds,color in names:
      if label != 'ignore':
        ts = time(kinds)
        if label=='idle':
          ts -= 5*write
          assert all(ts>=0)
        elif 'write' in label:
          ts = 5*write
        if plot:
          plots.append(pylab.bar(ns,scale*ts,bottom=scale*total,label=label,color=color,align='center'))
          labels.append(label)
        total += ts
    return total.sum()
  run(plot=1,scale=1/run(plot=0))
  for L in plots,labels:
    L[:2] = L[:2][::-1]
  ax = pylab.axes()
  pylab.xticks(ns,map(str,ns))
  pylab.xlim(35+.65,17-.65)
  pylab.ylim(0,.19)
  pylab.legend(plots,labels,loc='upper left',prop={'size':10})
  pylab.xlabel('slice (number of stones on the board)')
  pylab.ylabel('fraction of total time')
  ax.set_aspect(35)
  pylab.savefig('profile.pdf',transparent=1,bbox_inches='tight',pad_inches=0,dpi=40)
  pylab.show()
if 'profile' in sys.argv:
  profile()

def load():
  import pylab
  ns = asarray(range(17,36)[::-1])
  kinds = 'lines','line blocks','line nodes','blocks','block nodes'
  worst = 100*ones(37)
  worst[ns] = 1
  for kind in kinds:
    load = asarray([all_info.balance[n,kind] for n in ns])
    worst[ns] = maximum(worst[ns],load)
    pylab.plot(ns,load,label=kind)

  print()
  for lim in 1.1,1.2,1.3,1.4:
    good, = nonzero(worst<lim)
    lo,hi = min(good),max(good)
    print('Load within %g for slices [%d,%d]'%(lim,lo,hi))
    good = sum(all_info.walltime[n] for n in xrange(lo,hi+1))
    total = sum(all_info.walltime[n] for n in xrange(19,36))
    print('  wall fraction = %g s / %g s = %g'%(good,total,good/total))
    good = sum(all_info.times[n,'compute'] for n in xrange(lo,hi+1))
    total = sum(all_info.times[n,'compute'] for n in xrange(17,36))
    print('  compute fraction = %g s / %g s = %g'%(good,total,good/total))

  ax = pylab.axes()
  pylab.xticks(ns,map(str,ns))
  pylab.xlim(34,17)
  pylab.ylim(.9,2)
  pylab.xlabel('slice (number of stones on the board)')
  pylab.ylabel('max/min ratio')
  pylab.legend(loc='upper center',prop={'size':10})
  ax.set_aspect(5)
  pylab.savefig('balance.pdf',transparent=1,bbox_inches='tight',pad_inches=0,dpi=80)
  pylab.show()
if 'load' in sys.argv:
  load()

def messages(single=None):
  # Parameters
  dir = '../data/edison/project/tiny-1-history'
  ranks_per_node = 8
  ds = 1<<10
  dt = .001

  # Start logging
  print()
  Log.configure('message statistics',0,0,100)
  Log.write('single = %s'%single)

  # Grab compression ratios
  with Log.scope('parse log'):
    info = Info(dir+'/log')
    compression = asarray([info.compression.get(n,nan) for n in xrange(36+1)])

  # Read and sort history
  with Log.scope('read history'):
    history,ranks = read_all_history(dir)
    threads_per_rank = len(history)//ranks
    assert threads_per_rank==6
  with Log.scope('sort history'):
    def sort_by_events(events):
      return events[argsort(events[:,0])] if len(events) else events
    history = map(curry(map,sort_by_events),history)

  # Plot message statistics
  import pylab
  from matplotlib.ticker import FormatStrFormatter
  kinds = (request_send_kind,0),(response_send_kind,0),(output_send_kind,0),(output_send_kind,1)
  for k,(source_kind,special) in enumerate(kinds):
    if single and k != single[0]:
      continue
    with Log.scope('kind %s'%source_kind):
      steps = 1
      stats = message_statistics(history,ranks_per_node,threads_per_rank,source_kind,steps,compression)
      for t,type in enumerate('same-rank same-node different'.split()):
        if single and t != single[1]:
          continue
        with Log.scope(type):
          if not single:
            pylab.subplot(4,3,1+3*k+t)
            pylab.title('%s, %s, steps %d'%(source_kind,type,steps))
          Log.write('count = %d'%len(stats[type]))
          sizes = stats[type][:,0]
          times = stats[type][:,1]
          if source_kind==request_send_kind and steps==1:
            # Plot a 1D histogram since sizes = 8
            assert all(sizes==8)
            pylab.hist(times,weights=100/len(times)*ones_like(times),
                       bins=32,range=(0,sort(times)[99*len(times)//100]))
            pylab.xlabel('time (seconds)')
            pylab.axes().yaxis.set_major_formatter(FormatStrFormatter('%d%%'))
            if single:
              name = {(0,2):'request-latency.pdf'}[tuple(single)]
              pylab.axes().set_aspect(1/400)
              pylab.savefig(name,transparent=1,bbox_inches='tight',pad_inches=0,dpi=40)
          else:
            sizes = sizes/1024
            if special:
              pylab.hist(times[sizes==256],bins=64)
              pylab.xlabel('time (seconds)')
            else:
              if 1:
                random.seed(183712)
                I = sort(random.randint(0,len(sizes),size=1024)) if len(sizes) else []
                pylab.plot(sizes[I],times[I],'.')
              else:
                # Make a 2D histogram
                density,sizes,times = histogram2d(sizes,times,bins=32)
                Log.write('sizes = %g %g (%d)'%(sizes[0],sizes[-1],len(sizes)))
                Log.write('times = %g %g (%d)'%(times[0],times[-1],len(times)))
                # Plot the histogram
                if 1:
                  pylab.imshow(density,interpolation='nearest',origin='low',aspect='auto',
                               cmap='binary',
                               extent=[sizes[0],sizes[-1],times[0],times[-1]])
                else:
                  pylab.pcolor(density,cmap='RdBu')
                  pylab.xlim(sizes[0],sizes[-1])
                  pylab.ylim(times[0],times[-1])
              pylab.xlabel('size (KB)')
              pylab.ylabel('time (seconds)')
  pylab.show()
if 'messages' in sys.argv:
  i = sys.argv.index('messages')
  if len(sys.argv) > i+1:
    single = map(int,sys.argv[i+1].split(','))
    assert len(single)==2
  else:
    single = None
  messages(single)

def papi():
  Log.write('')
  Log.configure('papi',0,0,100)
  order = None
  for name in 'papi-1-issue papi-5-issue-noht papi-2-loadstore papi-3-cache papi-4-branch'.split():
    info = Info('../data/edison/project/%s/log'%name)
    def index(name):
      return info.papi_events.index(name) if name in info.papi_events else None
    cache_miss = index('PAPI_L3_TCM')
    instructions = index('PAPI_TOT_INS')
    cycles = index('PAPI_TOT_CYC')
    mispredict = index('PAPI_BR_MSP')
    conditional = index('PAPI_BR_CN')
    issue = 'PAPI_STL_ICY' in info.papi_events
    if order is None:
      order = [k for n,k in info.papi.keys() if n=='all']
      order = sorted(order,key=lambda k:-info.papi['all',k][0])
    lines = [[name]+info.papi_events
             +['bandwidth (GB/s)']*(cache_miss is not None)
             +['instructions/cycle']*(instructions is not None and cycles is not None)
             +['misprediction rate']*(mispredict is not None and conditional is not None)]
    for k in order:
      line = ['  '+k]+list(map(large,info.papi['all',k]))
      if cache_miss is not None:
        line.append('%.3f'%(64/2**30*info.papi['all',k][cache_miss]/info.times['all',k]))
      if instructions is not None and cycles is not None:
        line.append('%.3f'%(info.papi['all',k][instructions]/info.papi['all',k][cycles]))
      if mispredict and conditional:
        line.append('%.3f'%(info.papi['all',k][mispredict]/info.papi['all',k][conditional]))
      lines.append(line)
    lengths = zeros(len(lines[0]))
    for line in lines:
      lengths = maximum(lengths,map(len,line))
    for line in lines:
      Log.write('  '.join('%%%s%ds'%('-'*(i==0),n)%s for i,(n,s) in enumerate(zip(lengths,line))))
    Log.write('')
if 'papi' in sys.argv:
  papi()
