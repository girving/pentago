#!/usr/bin/env python

from __future__ import division
from other.core import *
from other.core.value import parser
from interface import *
import time

level = PropManager.add('level',21)
do_count = PropManager.add('count',False)
do_lowrank = PropManager.add('lowrank',False)
plot = PropManager.add('plot',0)
parser.parse('Pentago filter benchmarks')
level = level()

def count(data):
  with Log.scope('count causal'):
    if 0:
      counts = count_causal_cases(data).reshape(3**8,3)
    else:
      counts = count_outer_causal_cases(data).reshape(3**4,3)
    Log.write('counts shape = %s'%(counts.shape,))
  with Log.scope('report causal'):
    totals = sum(counts,axis=0)
    def prob(p,axis=-1):
      p = swapaxes(p,axis,-1)
      p = maximum(1e-20,p)
      p = p/sum(p,-1)[...,None]
      return swapaxes(p,axis,-1)
    def entropy(p,axis=-1):
      p = prob(p,axis)
      assert allclose(sum(p,-1),1)
      return -sum(p*log(maximum(p,1e-20)),axis)
    Log.write('totals = %s'%totals)
    Log.write('probabilities = %s'%prob(totals))
    Log.write('entropy = %g'%entropy(totals))
    prediction = counts.argmax(axis=-1)
    conditional = asarray([sum(counts*(prediction==n)[:,None],axis=0) for n in 0,1,2])
    Log.write('conditional counts = \n%s'%conditional)
    Log.write('conditional probabilities = \n%s'%prob(conditional))
    Log.write('conditional entropies = %s'%entropy(conditional))
    Log.write('conditional entropy = %s'%(sum(prob(conditional.sum(axis=-1),axis=0)*entropy(conditional))))
    Log.write('better entropy = %g'%(dot(prob(counts.sum(axis=-1)),entropy(counts))))
  with Log.scope('bytes'):
    counts = count_byte_cases(data.reshape(-1,2,4))
    e = dot(prob(counts.sum(axis=-1)),entropy(counts))
    Log.write('byte entropy = %g'%e)
    Log.write('byte compression = %g'%(e/8))
  with Log.scope('count rotations'):
    counts = count_rotation_cases(data)
    assert counts.shape==(4,3**4)
  with Log.scope('report rotations'):
    totals = counts.sum(axis=0)
    for k in argsort(totals)[::-1]:
      v123,v0 = divmod(k,3)
      v23,v1 = divmod(v123,3)
      v3,v2 = divmod(v23,3)
      Log.write('%d%d%d%d : %7d'%(v0,v1,v2,v3,totals[k]))
    for i in xrange(4):
      Log.write('entropy %d = %g'%(i,entropy(counts[i])))

def lowrank(data,plot=False):
  with Log.scope('lowrank'):
    # Rearrange data into a bit array
    shape = data.shape[:4]
    data = unpackbits(data.view(uint8)).reshape(shape+(2,4,4,4,4))
    data = data[:,:,:,:,0]
    data = data.swapaxes(3,6).swapaxes(1,4).swapaxes(2,4).swapaxes(3,5).reshape(*(4*array(shape)))
    # Measure raw entropy
    def entropy(p):
      p = asarray(p)
      return (-p*log(maximum(p,1e-20))-(1-p)*log(maximum(1-p,1e-20)))/log(2)
    def prob(axes=(0,1,2,3)):
      d = data.astype(float)
      for a in axes:
        d = d[...,None].swapaxes(a,-1).mean(axis=-1)
      return d
    p = prob()
    Log.write('p = %g, S = %g'%(p,entropy(p)))
    if plot:
      import pylab
    def splot(p,label,color='g'):
      if plot:
        p = sort(ravel(p)) 
        pylab.plot(arange(len(p))/len(p),p,color=color,label=label)
    entropies = []
    for i in xrange(4):
      for j in xrange(i+1,4):
        p = prob((i,j))
        entropies.append(entropy(p))
        Log.write('axes %d %d, p = %g, S = %g'%(i,j,mean(p),mean(entropy(p))))
        splot(p,label='%d %d'%(i,j),color='r')
    best_S = reduce(minimum,entropies)
    Log.write('best 2-axis entropy = %g'%mean(best_S))
    splot(best_S,label='best 2')
    if 1:
      for i in xrange(4):
        p = prob((i,))
        entropies.append(entropy(p))
        Log.write('axes %d, p = %g, S = %g'%(i,mean(p),mean(entropy(p))))
        splot(p,label='%d'%i,color='b')
      best_S = reduce(minimum,entropies)
      Log.write('best 3-axis entropy = %g'%mean(best_S))
      splot(best_S,label='best 3')
    if plot:
      pylab.legend()
      pylab.show()
      sys.exit(0)

def identity(data,shape=None):
  return data

def shuffle(data):
  shape = data.shape[:4]
  data = ravel(data.view(uint8))
  d = unpackbits(data).reshape(shape+(2,4,4,4,4))
  d = d.swapaxes(1,5).swapaxes(2,5).swapaxes(3,6).swapaxes(4,5).swapaxes(5,7).swapaxes(7,8)
  return packbits(d)

def unshuffle(data,shape):
  data = char_view(data)
  d = unpackbits(data).reshape(shape[0],4,shape[1],4,shape[2],4,shape[3],4,2)
  d = d.swapaxes(7,8).swapaxes(5,7).swapaxes(4,5).swapaxes(3,6).swapaxes(2,5).swapaxes(1,5)
  return packbits(d).view(uint64).reshape(shape+(2,4))

def popsort(data):
  data = data.reshape(-1,2,4)
  counts = super_popcounts(data)
  counts = counts[:,0] - counts[:,1]
  order = argsort(counts)
  data[:] = data[order]
  return interleave_help(data)

def char_view(data):
  return ravel(data).view(uint8)

def interleave_help(data):
  data = data.reshape(-1,2,4)
  interleave(data)
  return data

def uninterleave_help(data,shape):
  data = data.view(uint64).reshape(shape+(2,4))
  uninterleave(data.reshape(-1,2,4))
  return data

def compact_help(data):
  return compact(data.reshape(-1,2,4))

def uncompact_help(data,shape):
  return uncompact(data).reshape(shape+(2,4))

def driver():
  Log.configure('filter test',0,0,100)
  init_thread_pools(-1,-1)
  reader = supertensor_reader_t('data/section-32-44444444.pentago')
  header = reader.header
  random.seed(9454242)

  # Define filters
  filters = [('identity',identity,identity)
            ,('interleave',interleave_help,uninterleave_help)
            ,('shuffle',shuffle,unshuffle)
            ,('compact',compact_help,uncompact_help)
            ,('popsort',popsort,None)]

  # Loop through a few random blocks
  total_uncompressed = 0
  total_compressed = 0
  totals = dict((name,0) for name,_,_ in filters)
  wins = zeros(2)
  total = 0
  for i in xrange(32):
    with Log.scope('block'): 
      b = [random.randint(header.blocks[i]) for i in xrange(4)]
      Log.write('block shape = %s'%header.block_shape(b))
      compressed = reader.compressed_size(b)
      uncompressed = reader.uncompressed_size(b)
      total_compressed += compressed
      total_uncompressed += uncompressed
      Log.write('uncompressed size = %d'%uncompressed)
      Log.write('compressed size   = %d'%compressed)
      Log.write('base ratio = %g'%(compressed/uncompressed))
      data = reader.read_block(b)

      # Compute total wins, losses, and ties
      ltotal = 32*data.size
      lwins = zeros(2)
      for a in 0,1:
        lwins[a] += super_popcount(data[:,:,:,:,a,:].copy())
      outcomes = array([lwins[0],ltotal-sum(lwins),lwins[1]])
      Log.write('outcomes = %d %d %d, ratios = %g %g %g'%tuple(hstack([outcomes,outcomes/ltotal])))
      total += ltotal
      wins += lwins

      # Test the compression after each filter
      for name,filter,inverse in filters:
        d = filter(data.copy())
        fsize = len(compress(char_view(d),level))
        totals[name] += fsize
        Log.write('%s ratio = %g'%(name,fsize/uncompressed))
        if inverse is not None:
          d = inverse(d,data.shape[:4])
          assert all(data==d)

      # Optionally compute entropies
      if do_count():
        with Log.scope('count'):
          count(data)

      # More optional stuff
      if do_lowrank():
        lowrank(data,plot=plot())
  with Log.scope('totals'):
    Log.write('base ratio = %g'%(total_compressed/total_uncompressed))
    for name,_,_ in filters:
      Log.write('%s ratio = %g'%(name,totals[name]/total_uncompressed))
    outcomes = array([wins[0],total-sum(wins),wins[1]])
    Log.write('outcomes = %d %d %d, ratios = %g %g %g'%tuple(hstack([outcomes,outcomes/total])))
       
if __name__=='__main__':
  driver()
