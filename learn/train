#!/usr/bin/env python3
"""Pentago neural net training"""

import argparse
import datasets
import equivariant as ev
import haiku as hk
import jax
import jax.numpy as jnp
import numpy as np
import optax


def batches(*, batch):
  paths = [f'../data/edison/project/all/sparse-{n}.npy' for n in (16,17,18)]


def main():
  batch = 64
  layers = 4
  width = 128
  mid = 128
  log_every = 100
  lr = 1e-3
  key = jax.random.PRNGKey(7)

  # Parse arguments
  parser = argparse.ArgumentParser(description='Pentago train')
  parser.add_argument('--log', type=str, help='log file')
  options = parser.parse_args()

  # Logging
  if options.log:
    log_file = open(options.log, 'w')
    def slog(s):
      print(s)
      print(s, file=log_file)
      log_file.flush()
  else:
    slog = print

  # Load data
  dataset = datasets.SparseData(batch=batch, seed=7, counts=(16,17,18))

  # Define network
  @hk.transform
  def net(data):
    quads = data['quads']
    values = data['value']
    batch, = values.shape
    labels = jax.nn.one_hot(values + 1, num_classes=3)
    logits = ev.invariant_net(quads, layers=layers, width=width, mid=mid)
    loss = jnp.sum(labels * jax.nn.log_softmax(logits)) / -batch
    accuracy = (jnp.argmax(logits, axis=-1) == values + 1).astype(np.float32).mean()
    return loss, dict(loss=loss, accuracy=accuracy)

  # Initialize
  key, key_ = jax.random.split(key)
  params = net.init(key_, next(dataset.forever()))
  print(f'params = {sum(p.size for p in jax.tree_leaves(params)):,}')

  # Optimizer
  opt = optax.adam(lr)
  opt_state = opt.init(params)

  # Update step
  @jax.jit
  def update(params, opt_state, data):
    grads, metrics = jax.grad(lambda p: net.apply(p, None, data), has_aux=True)(params)
    updates, opt_state = opt.update(grads, opt_state)
    params = optax.apply_updates(params, updates)
    return params, opt_state, metrics

  # Train
  metrics = dict(loss=[], accuracy=[])
  for step, data in enumerate(dataset.forever()):
    params, opt_state, ms = update(params, opt_state, data)
    for s in metrics:
      metrics[s].append(ms[s])
    if step % log_every == 0:
      e = dataset.step_to_epoch(step)
      msg = f'step {step}, epochs {e:.3}, samples {step*batch}'
      for s, xs in metrics.items():
        msg += f', {s} {np.mean(xs):.3}'
        xs.clear()
      slog(msg)


if __name__ == '__main__':
  main()
